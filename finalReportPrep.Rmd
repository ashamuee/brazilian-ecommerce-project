---
title: "CYO Project Report - Delivery Estimation System"
author: "Asham Vohra"
date: "6/21/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview
Prediction systems play a cruical role in the modern world. With advent of technology and availability of data, these systems are being leveraged by retail chains, banks, colleges among other businesses. Depending on the use case, these systems are used to estimate delivery time, sales figures, carry out inventory management, predict occurrence of a disease, among others. 

Inspired by what all problems these systems can solve, we have attempted to build a delivery prediction system based on publically available [dataset of orders made at Olist Store](https://www.kaggle.com/olistbr/brazilian-ecommerce), a Brazilian ecommerce.

The dataset used here is hosted at [Kaggle website](https://www.kaggle.com). The dataset is provided by Olist itself, which is the largest department store in Brazilian marketplaces. Olist connects sellers to the customers. It is the sellers, who are responsible to fulfill any orders placed on the platform using Olist's logistic partners. 

The dataset consists of **100,000+** orders and for each order the dataset contains related details like product bought and from which category, customer who bought and his/her location, seller involved and many more attributes.

The delivery prediction system developed as part of the project, leverages the past orders, product category, delivery distance, customer location, actual delivery time and related attributes to predict delivery estimate for the new orders. 

The goal of the project was to build a delivery prediction system which can estimate number of hours required for delivery keeping RMSE(Root mean square error) minimal. 

In order to achieve this goal, we started by cleaning data, identifying right predictors, deriving insights from data already available to create new predictors. Once we had the dataset with us, we incrementally took a predictor, analysed its relationship with the number of hours of delivery, incorporated the predictor in our model after encoding, scaling it as required and tested our updated model against the test data. To ensure that the model performance was not due to random split of dataset, the model was trained and tuned using k fold cross validation and then only tested against the test dataset. Only if the predictor helped improve our metric i.e. RMSE, the predictor under analysis and evaluation was added to the model and the steps were repeated with new predictor. Otherwise the predictor was ignored

This report walks through the approach, analysis and evaluation carried out to achieve our delivery prediction system

# Analysis

## Data Wrangling
```{r Install or load packages,include=FALSE, echo = FALSE}
# TODO use conditional loading or installation of library
# Remove plotly related code for pdfs
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('lubridate')) install.packages('lubridate'); library('lubridate')
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
if (!require('geosphere')) install.packages('geosphere'); library('geosphere')
if (!require('caret')) install.packages('caret'); library('caret')
if (!require('randomForest')) install.packages('randomForest'); library('randomForest')
if (!require('knitr')) install.packages('knitr'); library('knitr')
```

An important step in using any public data set is converting it to usable form. In our case, the data set was available in multiple csv files, each file dedicated to a specific kind of information. Example: 

* There was a file for orders which had information about product bought, purchase time, delivery timestamp and other attributes. 
* Then there was a file with product details which had information about product category, product weight and other attributes.

Each of these files due to the varied dataset required different data wrangling steps to achieve a usable form which could then be unified for further analysis.

### Data wrangling for products data set

The data set here had product details like category name, dimensions and other attributes. Here the category name was in Portuguese. Some important attributes like product dimensions and weight were not populated for few of the products. To analyse this data properly, we carried out below steps:

* Read the concerned csv file and removed irrelevant columns for the analysis.
* Removed products where dimensions and related attributes were not available.
* Assigned default category name of UNCATEGORIZED for products where product_category_name was not available.
* Replaced product category names with English names where-ever mapping was available. The product categories for which equivalent English name mapping was not available were left untouched.

```{r Data wrangling-products data set, include=FALSE, echo=FALSE}
# read the data from source and remove irrelevant columns
products_dataset <- read.csv(file.path('data','olist_products_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) %>%
  select(-product_name_lenght,-product_description_lenght,-product_photos_qty)

# check how they are structured
products_dataset %>% head()
products_dataset %>% str()

# load the product category name translations
product_category_name_translation <- read.csv(file.path('data','product_category_name_translation.csv'),header=TRUE,stringsAsFactors = FALSE)

product_category_name_translation %>% head()

# convert product_name to english form wherever possible. If not available, existing product category name is retained
products_dataset <- products_dataset %>% 
  left_join(product_category_name_translation,by='product_category_name') %>% 
  mutate(product_category_name=if_else(is.na(product_category_name_english),
                                       product_category_name,
                                       product_category_name_english)) %>% 
  select(-product_category_name_english) 

# further remove products for which data is not available i.e is NA
products_dataset <- products_dataset %>% 
  filter(!is.na(product_weight_g) & !is.na(product_length_cm) & !is.na(product_height_cm) & !is.na(product_width_cm))

# assign default category name of UNCATEGORIZED where-ever product_category_name is blank.
products_dataset <- products_dataset %>%
  mutate(product_category_name=if_else(product_category_name=='','UNCATEGORIZED',product_category_name))
```

The wrangled data looked like below:
```{r Data wrangling result-products data set, echo=FALSE}
products_dataset %>% head(2) %>% as.matrix()  %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Product data set')
```

### Data wrangling for orders data set

The data set here had orders details like order id, associated customer, order status, purchase time, when was the order handed over to carrier, when was it delivered to customer and estimated delivery date and few other attributes.

This was a crucial dataset not only for us to build our delivery estimation system but to even identify the current performance metric i.e. RMSE for the approach Olist was using.

In order to leverage this dataset properly, we carried out below steps:

* Read the concerned csv file and removed irrelevant columns for the analysis.
* Parsed columns with date as characters and converted them to desired date type.
* Filtered out any orders where delivery was not made or where delivery was made but required delivery time columns were not available.

```{r Data wrangling-orders data set, include=FALSE, echo=FALSE}
# order data set with various delivery related times
# note each customer_id is unique per order
# order_purchase_timestamp -> Shows the purchase timestamp.
# order_approved_at/payment_approved_at -> Shows the payment approval timestamp.
# order_delivered_carrier_date/handed_over_to_carrier_date -> Shows the order posting timestamp. When it was handled to the logistic partner.
# order_delivered_customer_date --> Shows the actual order delivery date to the customer.
# order_estimated_delivery_date --> Shows the estimated delivery date that was informed to customer at the purchase moment.
orders_dataset <- read.csv(file.path('data','olist_orders_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) %>% 
  rename(payment_approved_at=order_approved_at,
         handed_over_to_carrier_date=order_delivered_carrier_date)  %>% 
  mutate(order_status=as.factor(order_status),
         order_purchase_timestamp=as_datetime(order_purchase_timestamp),
         payment_approved_at=as_datetime(payment_approved_at),
         handed_over_to_carrier_date=as_datetime(handed_over_to_carrier_date),
         order_delivered_customer_date=as_datetime(order_delivered_customer_date),
         order_estimated_delivery_date=as_datetime(order_estimated_delivery_date))

# TODO if we are not using payment_approved_at or few fields we can remove the filter logic based on that.
orders_dataset <- orders_dataset %>% 
  filter(order_status=='delivered') %>% 
  filter( !is.na(order_estimated_delivery_date ) & !is.na(order_delivered_customer_date ) & !is.na(handed_over_to_carrier_date) & !is.na(payment_approved_at) & !is.na(order_purchase_timestamp))

orders_dataset %>% head()
orders_dataset %>% str()
```

The wrangled data looks like below:
```{r Data wrangling result-orders dataset, echo=FALSE}
orders_dataset %>% head(2) %>% as.matrix() %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Orders data set')
```

### Data wrangling for orders items data set

The data set here had order item details like which product(s) were bought for a given order, who the seller was, price and freight value and shipping limit date. While most of the attributes were used to connect with other data sets, it was the shipping limit date which could be used along with product handed over to carrier date from orders dataset to identify any delays in the shipping process.

In order to leverage this dataset properly, we carried out below steps:

* Read the concerned csv file and removed irrelevant columns for the analysis.
* Parsed columns with date as characters and converted them to desired date type.

```{r Data wrangling-order items data set, include=FALSE, echo=FALSE}
# orders data with item related seller info
# order_item_id --->sequential number identifying number of items included in the same order.
# so if there are three items they will be nuber 1 , 2, 3 for the given order
# shipping_limit_date ---> Shows the seller shipping limit date for handling the order over to the logistic partner.
# freight_value --> item freight value item (if an order has more than one item the freight value is splitted between items)
order_items_dataset <- read.csv(file.path('data','olist_order_items_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) %>% mutate(shipping_limit_date=as_datetime(shipping_limit_date))  %>% select(-order_item_id)

order_items_dataset %>% str()
order_items_dataset %>% head()
```

The wrangled data looks like below:
```{r Data wrangling result-orders items dataset, echo=FALSE}
order_items_dataset %>% head(2) %>% as.matrix() %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Order Items\' data set')
```
### Data wrangling for geolocation data set

The data set here had geolocation data. It had zip code prefix, lat, lang, city and state details. However, there was no unique identifier in the dataset.

It is important to note that  Brazil uses [Postal Code Address(CEP)](https://codigo-postal.org/en-us/brazil/) which is 8-digit number created mainly from mail distribution objective. It is split into two parts of 5 and 3 digits resp. separated by a hyphen('-'). The first part helps identify the rough delivery area, while it is the second part which provides precision and helps one reach the desired street, neighbourhood.

So in the geolocation data set, zip code prefix refered to the first part of the CEP and it varied from 1 to 5 digits in the dataset available to us. Because the zip code prefix does not represent the precise value, it was not unique and had many duplicate values with varying value of lat, lng for same zip code prefix. 

In order to be able to use this data with other data sets available like customer location and seller location datasets, which are discussed later, we carried out below steps:

* Read the concerned csv file and removed irrelevant columns for the analysis.
* Calculated the mean of lat, lng for given zip code prefix.

```{r Data wrangling- geolocation data set, include=FALSE, echo=FALSE}
# geo location details
# in brazil while 5 digits zip code is good enough to identify state, it may not be correct to identify city
# it can have geolocation_zip_code_prefix shared across multiple places
# refer: https://codigo-postal.org/en-us/brazil/
# The Postal Code Address (CEP) is an eight-digit number set that has by main objective to guide and accelerate the distribution of objects sent through the national mail in Brazil. The current structure of the Brazilian postal code is 8 (eight) digits, divided into two parts:

# first part composed of 5 digits where each digit represents the 1) region, 2) sub-region, 3) sector, 4) subsector, 5) subsector divider;
# the second part is composed of 3 digits, separated by a hyphen from the first part and represents the Distribution Identifiers.
# You can navigate through states, then cities and finally neighborhoods and streets until you find the corresponding postal code.


# geolocation_dataset <- read.csv(file.path('data','olist_geolocation_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) 
geolocation_dataset <- read.csv(file.path('data','olist_geolocation_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) %>% select(-geolocation_city,-geolocation_state) 


geolocation_dataset %>% head()
geolocation_dataset %>% str()


# Important: many geolocation_city have same name but different ascent component. Example: niteroi and niterói
# intially we can see 
# geolocation_dataset %>% dplyr::count(geolocation_zip_code_prefix,geolocation_city,geolocation_state) %>% nrow()

# post transformation to resolve any Accent or special characters from the city name
# geolocation_dataset <- geolocation_dataset %>% mutate(geolocation_city=stri_trans_general(geolocation_city,"Any-ASCII"))

# above is not done as the way zip codes are in brazil, first five digits can correspond to different cities and so we will remove the city. We also removed state as there seems to be incorrect entries in the sellers data. This either needs to be fixed or we can limit ourselves to lat/long value


# geolocation_dataset %>% dplyr::count(geolocation_zip_code_prefix,geolocation_city,geolocation_state) %>% nrow()

# as each geolocation_zip_code_prefix can have many data points, we will limit these to one by taking mean for lat, long location
geolocation_dataset <- geolocation_dataset %>% group_by(geolocation_zip_code_prefix) %>% summarise(geolocation_lat=mean(geolocation_lat),geolocation_lng=mean(geolocation_lng)) %>% ungroup()
#geolocation_dataset <- geolocation_dataset %>% group_by(geolocation_zip_code_prefix,geolocation_city,geolocation_state) %>% summarise(geolocation_lat=mean(geolocation_lat),geolocation_lng=mean(geolocation_lng)) %>% ungroup()

# TODO review it
#%>% mutate(geolocation_state=as.factor(geolocation_state)) 
# TODO review if geolocation_zip_code_prefix and geolocation_city can have multiple states with them.

# remove whitespace before and after reduces one city
# still issues are there and can be seen by
# zip_codes_of_interest <- geolocation_dataset %>% mutate(geolocation_city=str_trim(geolocation_city)) %>% dplyr::count(geolocation_zip_code_prefix) %>% filter(n>1)  %>% pull(geolocation_zip_code_prefix)

# geolocation_dataset %>% filter(geolocation_zip_code_prefix %in% zip_codes_of_interest) %>% view()
# to filter out duplicates
# we need not worry about city or state, we can pick any as long as lat, lng values are similar
```

The wrangled data looks like below:
```{r Data wrangling result-geolocation dataset, echo=FALSE}
geolocation_dataset %>% head(2) %>% summarise_all(as.character) %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Geolocation data set')
```

### Data wrangling for customers and sellers data set

There were two data sets one for customers and one for sellers. Apart from identifier ids like customer_unique_id, seller_id, both the datasets had similar columns i.e. zip code prefix, for which details were in geolocation data set and city and state.

To be able to leverage either of these datasets for analysis later, we carried out below steps:

* Read the concerned csv file and removed irrelevant columns for the analysis.
* Combined sellers dataset data individually with geolocation dataset in order to capture seller lat,lng. Similar operation was carried out for customers data set.
* Remove sellers or customers for which geolocation details are not available as delivery or even its estimation is not possible without the critical fields.

```{r Data wrangling-customers data set, include=FALSE, echo=FALSE}
# customers data set  with zip code prefix and can be used to uniquely identify a customer
# customer_id ----> key to the orders dataset. Each order has a unique customer_id.
# customer_zip_code_prefix --> first five digits of customer zip code
customers_dataset <- read.csv(file.path('data','olist_customers_dataset.csv'),header=TRUE,stringsAsFactors = FALSE) 
# %>% mutate(customer_zip_code_prefix=as.factor(customer_zip_code_prefix),customer_id=as.character(customer_id ))

customers_dataset %>% head()
customers_dataset %>% str()
```

```{r Data wrangling-sellers data set, echo=FALSE, include=FALSE}
# seller data set with zip code prefix
# seller_zip_code_prefix --> first 5 digits of seller zip code
sellers_dataset <- read.csv(file.path('data','olist_sellers_dataset.csv'),header=TRUE,stringsAsFactors = FALSE)
# TODO review if we need it
# %>% mutate(seller_zip_code_prefix=as.factor(seller_zip_code_prefix),seller_id=as.character(seller_id ))

sellers_dataset %>% head()
sellers_dataset %>% str()
```

```{r Refine sellers dataset, include=FALSE, echo=FALSE}
# Filter out data where sellers location details are not available
#
# Important: many geolocation_city have same name but different ascent component. Example: niteroi and niterói
# These all need to be handled in data wrangling


# we noticed some seller_zip_code_prefix are not present in geolocation dataset. So we will ignore them
sellers_to_ignore <- sellers_dataset %>% anti_join(geolocation_dataset,by=c('seller_zip_code_prefix'='geolocation_zip_code_prefix')) 

order_items_dataset %>% inner_join(sellers_to_ignore,by='seller_id') %>% nrow()
# while there are decent number of order items for the concerned sellers, we will ignore them as we will still have sufficient data for analysis.


# let's use the one of interest
sellers_dataset <- sellers_dataset %>% inner_join(geolocation_dataset,by=c('seller_zip_code_prefix'='geolocation_zip_code_prefix')) %>% rename(geolocation_lat_seller=geolocation_lat,geolocation_lng_seller=geolocation_lng)

# TODO there seems to be an issue (Should be resolved now)
# geolocation_dataset seems to have 4 entries for same zip code . example 13454
# sellers_dataset %>% inner_join(geolocation_dataset,by=c('seller_zip_code_prefix'='geolocation_zip_code_prefix')) %>% dplyr::count(seller_id) %>% slice_max(order_by=n,n=5)

# we tried another approach by joining over all zip codee, city and state but it led to no match
# sellers_dataset %>% mutate(seller_city=stri_trans_general(seller_city,"Any-ASCII")) %>% inner_join(geolocation_dataset,by=c('seller_zip_code_prefix'='geolocation_zip_code_prefix','seller_city'='geolocation_city','seller_state'='geolocation_state')) %>% str()
# TODO -- if we analyse we can see city and state for seller data differ in both datasets. so best to stick to zip code. city and state are prone to errors.
# we decided against using city and state.
```

The wrangled sellers dataset looks like below:
```{r Refined sellers dataset result, echo=FALSE}
sellers_dataset %>% head(2) %>% as.matrix()  %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Sellers data set')
```


```{r Refine customers data set, include=FALSE, echo=FALSE}
# similarly let see customers for whom we don't have data in geolocation_dataset
customers_to_ignore <- customers_dataset %>% anti_join(geolocation_dataset,by=c('customer_zip_code_prefix'='geolocation_zip_code_prefix')) 


orders_dataset %>% inner_join(customers_to_ignore,by='customer_id') %>% nrow()
# while there are decent number of orders for these customers, we will ignore them as we will still have sufficient data for analysis.

# let's use customers of interest
customers_dataset <- customers_dataset %>% inner_join(geolocation_dataset,by=c('customer_zip_code_prefix'='geolocation_zip_code_prefix')) %>% rename(geolocation_lat_customer=geolocation_lat,geolocation_lng_customer=geolocation_lng) 
```

The wrangled customers dataset looks like below:
```{r Refined customers dataset result, echo=FALSE}
customers_dataset %>% head(2) %>% as.matrix()  %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Customers data set')
```


```{r Combine data sets, include=FALSE, echo=FALSE}
# we can combine orders delivery information (orders_dataset) with orders items and seller related info (order_items_dataset)
# orders_dataset %>% inner_join(order_items_dataset,by='order_id') %>% head()

# let's combine with seller details
# orders_dataset %>% inner_join(order_items_dataset,by='order_id') %>% inner_join(sellers_dataset,by='seller_id') %>% head()

# let's combine with unique customer and its location dataset
# orders_dataset %>% inner_join(order_items_dataset,by='order_id') %>% inner_join(sellers_dataset,by='seller_id') %>% inner_join(customers_dataset,by='customer_id') %>% select(-customer_id) %>% head()

# let's combine with products data as well
# orders_dataset %>% inner_join(order_items_dataset,by='order_id') %>% inner_join(sellers_dataset,by='seller_id') %>% inner_join(customers_dataset,by='customer_id') %>% inner_join(products_dataset,by='product_id') %>% select(-customer_id,-order_status,-seller_city,-seller_state,-customer_city,-customer_state) %>% head()

# so raw data
raw_data <- orders_dataset %>% 
  inner_join(order_items_dataset,by='order_id') %>%
  inner_join(sellers_dataset,by='seller_id') %>% 
  inner_join(customers_dataset,by='customer_id') %>%  
  inner_join(products_dataset,by='product_id') %>%
  mutate(order_purchase_timestamp=as.numeric(order_purchase_timestamp),
         product_id=as.factor(product_id), 
         seller_id=as.factor(seller_id),
         seller_zip_code_prefix=as.factor(seller_zip_code_prefix),
         customer_unique_id=as.factor(customer_unique_id),
         customer_zip_code_prefix=as.factor(customer_zip_code_prefix),
         product_category_name=as.factor(product_category_name),
         customer_zip_code_prefix=str_pad(customer_zip_code_prefix, c(5),pad=c('0'),side='right')) %>%
  select(-customer_id,-order_status,-seller_city,-seller_state,-customer_city,-order_id,-product_id,-seller_zip_code_prefix,-customer_unique_id)
```


```{r RMSE, include=FALSE}
# Performance metric
RMSE <- function(true_outcomes, predicted_outcomes) {
  sqrt(mean((true_outcomes - predicted_outcomes)^2))
}
```

```{r Current RMSE, include=FALSE, echo = FALSE}
# current RMSE can be calculated by finding number of hours for predicted delivery time given by order_estimated_delivery_date vs actual outcome/number of hours give by order_delivered_customer_date
# However, note that order_estimated_delivery_date has no timestamp, so we will remove timestamp component, round date using floor_date, which means any delivery done during the day say at 2017-10-10 21:25:13 is treated to be done on 2017-10-10

# first we convert it to desired date
# then we covert date to numeric i.e. to convert it to seconds
# then we calculate time_taken_from_order_to_delivery, estimated_time_from_order_to_delivery in seconds
data_for_rmse <- raw_data %>%
  select(order_purchase_timestamp,order_delivered_customer_date,order_estimated_delivery_date) %>%
  mutate(order_delivered_customer_date_low=floor_date(order_delivered_customer_date,unit="day"),
         order_delivered_customer_date_high=ceiling_date(order_delivered_customer_date,unit="day")) %>% 
  mutate(order_delivered_customer_date_low=as.numeric(order_delivered_customer_date_low),
         order_delivered_customer_date_high=as.numeric(order_delivered_customer_date_high),
         order_estimated_delivery_date=as.numeric(order_estimated_delivery_date))  %>%
  mutate(time_taken_from_order_to_delivery_rangemax=order_delivered_customer_date_high-order_purchase_timestamp,
         time_taken_from_order_to_delivery_rangemin=order_delivered_customer_date_low-order_purchase_timestamp,
         estimated_time_from_order_to_delivery=order_estimated_delivery_date-order_purchase_timestamp) %>% 
  mutate(estimated_time_from_order_to_delivery=estimated_time_from_order_to_delivery/3600,
         time_taken_from_order_to_delivery_rangemax = time_taken_from_order_to_delivery_rangemax/3600,
         time_taken_from_order_to_delivery_rangemin = time_taken_from_order_to_delivery_rangemin/3600) %>%
  select(estimated_time_from_order_to_delivery,time_taken_from_order_to_delivery_rangemax,time_taken_from_order_to_delivery_rangemin)


RMSE_value_based_on_max <- RMSE(data_for_rmse$time_taken_from_order_to_delivery_rangemax,data_for_rmse$estimated_time_from_order_to_delivery)
# 359.9466

RMSE_value_based_on_min <- RMSE(data_for_rmse$time_taken_from_order_to_delivery_rangemin,data_for_rmse$estimated_time_from_order_to_delivery)
# 377.9515

# if we look at graph we can  see there is huge difference between estimated data and actual delivery date
# it is possible some products are bulky or require differen mode of transport like ship 
data_for_rmse %>% mutate(diff=estimated_time_from_order_to_delivery-1/2*(time_taken_from_order_to_delivery_rangemax+time_taken_from_order_to_delivery_rangemin)) %>% ggplot(aes(diff)) + geom_histogram(binwidth = 24*2) + xlab('Estimation error where each bar represents 2 days')

rm(data_for_rmse)
```

```{r Prepare final wrangled data set, include=FALSE}
# we will predict number of hours to deliver based on various predictors. This seems more appropriate. Though as a result of this, we won't be able to use night, day time data of purchase which may influence delivery time (say to carrier it is informed only next day)
wrangled_data <- raw_data %>%
  mutate(order_delivered_customer_date=as.numeric(order_delivered_customer_date)) %>%
  mutate(number_of_hours=(order_delivered_customer_date-order_purchase_timestamp)/3600) %>%
  select(-order_delivered_customer_date,-order_estimated_delivery_date)
```

Having wrangled the datasets individually we combined them into a single dataset. While the dataset had many attributes, based on their frequency and analysis, we zeroed on the below fields. In addition, it is important to note that for model development we created outcome column number_of_hours based on existing fields i.e. order_delivered_customer_date and order_purchase_timestamp as this is what we would want to predict whenever we get a new order i.e. given this order, how many number of hours are required to deliver the product to the customer.

The wrangled dataset after incorporating various datasets available to us looked like below:
```{r Final wrangled data,echo=FALSE}
wrangled_data %>% head(2) %>% as.matrix()  %>% t() %>% 
  knitr::kable(col.names=c('Example Value1','Example Value2'), caption='Final wrangled data set')
```

### Performance Metric

Before we dived into building our delivery prediction system, we identified our metric of choice i.e. RMSE for evaluating current delivery estimates being made by Olist and for comparing our delivery prediction system against that, in addition to improving our system as we built it.

*  RMSE is the root mean square error and that's what was used for this project to evaluate models and to optimize them for fitment.
* As we know, $RMSE = sqrt( 1/N * sum((\hat{y}-y)^2) )$
    + Here, $\hat{y}$ is the prediction. In context of this project, predicted number of hours for delivering the order item,
    + and y is the actual outcome. In context of this project, actual number of hours taken for delivering the order item.

#### Current RMSE

Before we dived into building our delivery prediction system, we looked into current RMSE. To calculate this, we leveraged order_estimated_delivery_date i.e. estimated delivery date and order_delivered_customer_date i.e. actual delivery timestamp, which was available in orders data set.

While order_estimated_delivery_date did not have time details, order_delivered_customer_date did. Since order_delivered_customer_date could be rounded off to same day or next day, we computed range of RMSE which can be calculated using either of the approach.

This RMSE i.e. our performance metric was later used as benchmark for modeling. The delivery prediction system being built attempted to improve on this metric.

Below were the current RMSE calculations based on how we interpret the actual delivery timestamp.
```{r Range of current rmse, echo=FALSE}
performance_metric <- data.frame(type=character(),value=numeric()) %>% 
  add_row(type='Current RMSE Max',value=RMSE_value_based_on_max) %>% 
  add_row(type='Current RMSE Min',value=RMSE_value_based_on_min) 

performance_metric %>% knitr::kable(caption='Performance Metric(RMSE) Summary')
```


```{r Cleanup and save required dataset, include=FALSE, echo=FALSE}
save(wrangled_data,file='rda/wrangled_data.rda')
rm(geolocation_dataset, order_items_dataset, orders_dataset, product_category_name_translation, products_dataset, sellers_dataset, sellers_to_ignore, customers_dataset, customers_to_ignore, raw_data)
```


```{r Method to derive distance data, include = FALSE}
# we will use distGeo from geosphere package to compute distance in km between seller and customer. considered to be highly accurate. if it takes more time, we can consider using distVincentyEllipsoid or distHaversine as we are fine with accuracy of a km.
extract_distance_between_seller_customer <- function(df) { 
  df %>% mutate(distance_between_two_points=round(distGeo(
    matrix(c(geolocation_lng_seller,geolocation_lat_seller),ncol=2),
    matrix(c(geolocation_lng_customer,geolocation_lat_customer),ncol=2)
    )/1000,2
    )) %>% select(-geolocation_lat_customer,-geolocation_lng_customer,-geolocation_lat_seller,-geolocation_lng_seller)
}
```

```{r Method to reduce levels in customer_zip_code_prefix, include = FALSE}
# trimming zip code to three digits to be able to extract zip code component which represents region, sub-region and sector data.
compute_rough_customer_location <- function(df) {
  df %>% mutate(customer_zip_code_prefix=str_pad(customer_zip_code_prefix, c(3),pad=c('0'),side='right')) %>% 
    mutate(customer_loc = as.numeric(str_extract(customer_zip_code_prefix,"\\d\\d\\d"))) 
  #%>% select(-customer_zip_code_prefix)
}
```

```{r Method to derive delay in handover to carrier, include = FALSE}
# calculated in hours
get_delay_in_handover_to_carrier_per_seller_id <- function(df) {
  df %>% mutate(delay= (as.numeric(handed_over_to_carrier_date) -as.numeric(shipping_limit_date))/3600)  %>% 
    group_by(seller_id) %>% 
    summarise(mean_delay_in_handover=mean(delay))
}
```

```{r Get delay in payment approval based on customer zip code prefix, include = FALSE}
# calculated in hours
# can be due to fraud check etc.
get_delay_in_payment_approval_per_customer_zip_code <- function(df) {
  df %>% mutate(payment_approved_at=as.numeric(payment_approved_at)) %>%
    mutate(time_to_approve_payment_hours=(payment_approved_at-order_purchase_timestamp)/3600) %>% 
    group_by(customer_zip_code_prefix) %>% 
    summarise(mean_delay_in_payment_approval=mean(time_to_approve_payment_hours))
}
```

```{r Method to compute volume from available fields, include = FALSE}
# compute volume
compute_volume_using_product_info <- function(df) {
  df %>% mutate(volume=product_length_cm*product_height_cm*product_width_cm) %>%
    select(-product_length_cm,-product_height_cm,-product_width_cm)
}
```

## Paritioning dataset for training and validation  

Before using the wrangled data for analysis and data modeling, we partitioned the data into training and validation data sets. The idea was to keep validation data set aside and use only training data for any analysis, model development and tuning. 

A split of 80/20 was made here between training and validation set to ensure we have enough data points to train and to validate the results. Secondly, the split was done such that distribution of outcome i.e. number_of_hours was similar in both training and test data.

The data sets were named as below for furture reference:

* training data set as **training_dataset** 
* validation data set as **validation_dataset**

```{r Split data into training and validation set, include = FALSE, echo = FALSE}
# Split data into training and validation set, where validation set will be used later
set.seed(1,sample.kind = 'Rounding')
test_indices <- createDataPartition(wrangled_data$number_of_hours,times=1,p=0.2,list=FALSE)

training_dataset <- wrangled_data[-test_indices,]
validation_dataset <- wrangled_data[test_indices,]

# ensure validation_dataset has products only for concerned product categories and seller_ids which are in training_dataset 
validation_dataset <- validation_dataset %>%
  semi_join(training_dataset,by='product_category_name') %>%
  semi_join(training_dataset,by='seller_id') %>% 
  semi_join(training_dataset,by="customer_zip_code_prefix")
## TODO review if we want to change this join
# validation_dataset <- validation_dataset %>% semi_join(training_dataset,by='seller_id')

rm(test_indices)
```

Below were the details about the elements in each of the partitioned datasets.
```{r Basic info about training and validation dataset,  echo= FALSE}
# The partitioned data were named training_dataset and validation_dataset, where training_dataset was our training data set and validation_dataset was our validation data set, which we kept aside as planned earlier. 

data.frame(data_set=c("Training data set","Validation data set"),name=c('training_dataset','validation_dataset'), count=c(nrow(training_dataset),nrow(validation_dataset))) %>% knitr::kable()
```

For analysis, we used only the training dataset.

Since we needed to build delivery prediction system which could estimate number of hours required for delivery for new orders, while maintaining minimum RMSE, we used our intution and understanding of the domain to guide us in deriving insights from available predictors. The same are shared below:

* _**Distance between seller and customer**_ could likely influence delivery estimate.
* _**Delay in payment approval**_ could influence delivery time as it would delay shippment from the seller. This could be related to customer zip code as often some customer locations require fraud analysis before payment is approved.
* _**Delay in handover of product**_ from seller to carrier would influence delivery time as any time spent there is wasted. This could be seller related as some sellers maybe known to take more time in processing order compared to other sellers. 
* Some _**customer locations**_ maybe difficult to reach or need special delivery mechanism due to their remote nature. Such locations may need more delivery time compared to other locations irrespective of the distance involved. We need not analyse for each customer location but a rough area could be used based on combination of zip codes.
* _**Weight of the product**_ could influence delivery time as heavy items say bed, furniture may be transported slowly while lighter items maybe shipped more quickly.
* _**Price of the product**_ could influence delivery time. Expensive items may require considerable more attention and could influence delivery like priority shipping or longer delivery time due to caution.
* _**Volume of the product**_ could influence delivery time as smaller products can be shipped together while others may need separate truck and therefore more time for dedicated truck to be available.
* _**Product category**_ could be used for analysis as different product categories would have different packing, assembly, processing requiremts and shelf life would could lead to impact in delivery time. 
* _**Freight value**_ could indicate complexity of shipping like fragility of the product, distance, toll booth charges on the way among others. This could be considered for analysis.
* _**Customer state**_ could influence the delivery estimate due to state border checks, paper work before goods delivery among others.
* Different _**sellers**_ may take different amount of time or sell specific type of products which may require different shipping time. So products from a seller selling apparels may be delivered quickly while products from one selling customised products or say furniture may take relatively more time. This could be useful information for predicting delivery time.













To start building our algorithm, we further paritioned our training data set i.e. training_dataset into a split of 80/20 between train_subset and test_subset to ensure we use only the train_subset for training and tuning the model and test_subset to evaluate the model and measure RMSE. This would ensure there is no data leak. The split like earlier was done such that distribution of outcome i.e. number_of_hours was similar in both training and test data







TODO
Use target encoding for categorical variables
Use preprocess for scaling data against training data set. Then use mean, sd from this trained data for test data.


Derived data set should be generated later on observations
- geolocation usage to capture distance
- delay and mean delay in handling to carrier
- number of hours for delivery should be generated later

We use training_dataset and split into into train and test set. So that training_dataset is sufficient to fine tune the model
```{r Split data for training, include=FALSE}
# Let's split training_dataset into two parts
set.seed(1,sample.kind = 'Rounding')
training_dataset <- training_dataset %>% compute_volume_using_product_info() %>% extract_distance_between_seller_customer() %>% compute_rough_customer_location()

test_indices <- createDataPartition(training_dataset$number_of_hours,times=1,p=0.2,list=FALSE)

train_subset <- training_dataset[-test_indices,]
test_subset <- training_dataset[test_indices,]

# ensure test_subset has products only for concerned product categories and seller_ids which are in train_subset
test_subset <- test_subset %>% semi_join(train_subset,by='product_category_name') %>%
  semi_join(train_subset,by='seller_id') %>% 
  semi_join(train_subset,by="customer_zip_code_prefix") %>% 
  semi_join(train_subset,by="customer_loc")

rm(test_indices)
```


==TODO note penalty data should be calculated again if train_subset is changed. Only trained data should be used for test, so that there is no data leak.

== TODO additive smoothing/Bayes estimator with target encoding

```{r Dataframe to store target encoding weights, include=FALSE}
target_encoding_weights <- data.frame(effect=character(0),weight=double(0)) 
```

```{r Prepare delay in handover to carried data, include = FALSE}
# prepare delay_in_handover_to_carrier_data based on regularisation weight we have identified
prepare_delay_in_handover_to_carrier <- function(train_df, weight_to_use) {
  global_mean <- mean(train_df %>% 
                        get_delay_in_handover_to_carrier_per_seller_id() %>% 
                        pull(mean_delay_in_handover))

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_df$number_of_hours,p=0.2,times=10,list=FALSE)

  delay_in_handover_to_carrier_data_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]
  
      delay_in_handover_to_carrier_data <- train_weight_set %>% 
        get_delay_in_handover_to_carrier_per_seller_id()
      
      delay_in_handover_to_carrier_data
    }
  )

  dhc <- delay_in_handover_to_carrier_data_list[[1]]
  for (index in 2:10) {
     dhc <- dhc %>% full_join(delay_in_handover_to_carrier_data_list[[index]],by='seller_id', suffix=c("1",index))
  }

  # wherever value is NA, we have used global mean
  dhc <- dhc %>% mutate(across(-seller_id,~if_else(is.na(.x),global_mean,.x)))
  
  # as different partitions may not have exactly same data set combined the results
  delay_in_handover_to_carrier_data <- tibble(dhc[,1],
                                              mean_delay_in_handover=rowMeans(dhc[,-1],
                                                                              na.rm = TRUE))
  
  #delay_in_handover_to_carrier_data is ready
  delay_in_handover_to_carrier_data
}
```

```{r Prepare delay in payment approval, include = FALSE}
# prepare delay_in_payment_approval based on regularisation weight we have identified
prepare_delay_in_payment_approval <- function(train_df, weight_to_use) {
  global_mean <- mean(train_df %>% 
                        get_delay_in_payment_approval_per_customer_zip_code() %>% 
                        pull(mean_delay_in_payment_approval))

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_df$number_of_hours,p=0.2,times=10,list=FALSE)

  delay_in_payment_approval_data_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]
  
      delay_in_payment_approval_data <- train_weight_set %>% 
        get_delay_in_payment_approval_per_customer_zip_code()
      
      delay_in_payment_approval_data
    }
  )

  dpa <- delay_in_payment_approval_data_list[[1]]
  for (index in 2:10) {
     dpa <- dpa %>% full_join(delay_in_payment_approval_data_list[[index]],by='customer_zip_code_prefix', suffix=c("1",index))
  }

  # wherever value is NA, we have used global mean
  dpa <- dpa %>% mutate(across(-customer_zip_code_prefix,~if_else(is.na(.x),global_mean,.x)))
  
  # as different partitions may not have exactly same data set combined the results
  delay_in_payment_approval_data <- tibble(dpa[,1],
                                              mean_delay_in_payment_approval=rowMeans(dpa[,-1],
                                                                              na.rm = TRUE))
  
  #delay_in_payment_approval_data is ready
  delay_in_payment_approval_data
}
```

```{r Prepare product_category effect based on target encoding, include = FALSE}
# prepare product_category_effect based on regularisation weight we have identified
prepare_product_category_effect <- function(train_df, weight_to_use) {
  global_mean <- mean(train_df$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_df$number_of_hours,p=0.2,times=10,list=FALSE)

  product_category_effects_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]
  
      product_category_effects <- train_weight_set %>% 
        group_by(product_category_name) %>%
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight_to_use*global_mean)/(n+weight_to_use)) %>% 
        select(-n) %>% rename()
      
      product_category_effects
    }
  )

  pce <- product_category_effects_list[[1]]
  for (index in 2:10) {
     pce <- pce %>% full_join(product_category_effects_list[[index]],by='product_category_name', suffix=c("1",index))
  }

  # wherever value is NA, we have used global mean
  pce <- pce %>% mutate(across(-product_category_name,~if_else(is.na(.x),global_mean,.x)))
  
  # as different partitions may not have exactly same data set combined the results
  product_category_effects <- tibble(pce[,1], product_category_effect=rowMeans(pce[,-1],na.rm = TRUE))
  
  #product_category effects are ready
  product_category_effects
}
```

```{r Prepare seller_id effect based on target encoding, include = FALSE}
# prepare seller_id_effect based on regularisation weight we have identified
prepare_seller_id_effect <- function(train_df, weight_to_use) {
    global_mean <- mean(train_df$number_of_hours)
    
    set.seed(1,sample.kind='Rounding')
    test_weight_indices <- createDataPartition(train_df$number_of_hours, p=0.2,times=10,list=FALSE)
    
    seller_id_effects_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]

      seller_id_effects <- train_weight_set %>% 
        group_by(seller_id) %>%
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight_to_use*global_mean)/(n+weight_to_use)) %>% 
        select(-n) %>% rename()
    
      seller_id_effects
    })
    
    
    sie <- seller_id_effects_list[[1]]
    for (index in 2:10) {
       sie <- sie %>% 
         full_join(seller_id_effects_list[[index]],by='seller_id', suffix=c("1",index))
    }
    
    # wherever value is NA, we have used global mean
    sie <- sie %>% mutate(across(-seller_id,~if_else(is.na(.x),global_mean,.x)))
    
    # as different partitions may not have exactly same data set combined the results
    seller_id_effects <- tibble(sie[,1], seller_id_effect=rowMeans(sie[,-1],na.rm = TRUE))
    
    #seller id effects are ready
    seller_id_effects
}
```

```{r Prepare customer_state effect based on target encoding, include = FALSE}
# prepare consumer_state_effect based on regularisation weight we have identified
prepare_customer_state_effect <- function(train_df, weight_to_use) {
  global_mean <- mean(train_df$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_df$number_of_hours,p=0.2,times=10,list=FALSE)

  customer_state_effects_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]
  
      customer_state_effects <- train_weight_set %>% 
        group_by(customer_state) %>%
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight_to_use*global_mean)/(n+weight_to_use)) %>% 
        select(-n) %>% rename()
      
      customer_state_effects
    }
  )

  cse <- customer_state_effects_list[[1]]
  for (index in 2:10) {
     cse <- cse %>% 
       full_join(customer_state_effects_list[[index]],by='customer_state', suffix=c("1",index))
  }

  # wherever value is NA, we have used global mean
  cse <- cse %>% mutate(across(-customer_state,~if_else(is.na(.x),global_mean,.x)))
  
  # as different partitions may not have exactly same data set combined the results
  customer_state_effects <- tibble(cse[,1], customer_state_effect=rowMeans(cse[,-1],na.rm = TRUE))
  
  #customer state effects are ready
  customer_state_effects
}
```

```{r Prepare customer_loc effect based on target encoding, include = FALSE}
# prepare customer_loc_effect based on regularisation weight we have identified
prepare_customer_loc_effect <- function(train_df, weight_to_use) {
  global_mean <- mean(train_df$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_df$number_of_hours,p=0.2,times=10,list=FALSE)

  customer_loc_effects_list <- lapply(1:10, function(index) {
      train_weight_set <- train_df[-test_weight_indices[,index],]
  
      customer_loc_effects <- train_weight_set %>% 
        group_by(customer_loc) %>%
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight_to_use*global_mean)/(n+weight_to_use)) %>% 
        select(-n) %>% rename()
      
      customer_loc_effects
    }
  )

  cle <- customer_loc_effects_list[[1]]
  for (index in 2:10) {
     cle <- cle %>% full_join(customer_loc_effects_list[[index]],by='customer_loc', suffix=c("1",index))
  }

  # where-ever value is NA, we have used global mean
  cle <- cle %>% mutate(across(-customer_loc,~if_else(is.na(.x),global_mean,.x)))

  # as different partitions may not have exactly same data set combined the results
  customer_loc_effects <- tibble(cle[,1], customer_loc_effect=rowMeans(cle[,-1],na.rm = TRUE))
  
  #customer loc effects are ready
  customer_loc_effects
}
```

```{r Enhance training and test dataset for delay in handover to carrier, include=FALSE}
enhance_datasets_using_delay_in_handover_to_carrier <- function(mean_delay_in_handover_to_carrier_data,train_df,test_df,cleanup) {
  #we will use mean_delay_in_handover_to_carrier_data computed using training data in test data.
  train_df <- train_df %>% left_join(mean_delay_in_handover_to_carrier_data,by='seller_id') 
  test_df <- test_df %>% left_join(mean_delay_in_handover_to_carrier_data,by='seller_id')
  
  #cleanup
  if (cleanup) {
    train_df <- train_df %>% select(-handed_over_to_carrier_date,-shipping_limit_date)
    test_df <- test_df %>% select(-handed_over_to_carrier_date,-shipping_limit_date)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and test dataset for delay in payment approval, include=FALSE}
enhance_datasets_using_delay_in_payment_approval <- function(delay_in_payment_approval_data,train_df,test_df,cleanup) {
  #we will use delay_in_payment_approval_data computed using training data in test data.  
  train_df <- train_df %>%
    left_join(delay_in_payment_approval_data,by='customer_zip_code_prefix')
  
  test_df <- test_df %>% left_join(delay_in_payment_approval_data,by='customer_zip_code_prefix')
  
  #cleanup
  if (cleanup) {
    train_df <- train_df %>%
      select(-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
    test_df <- test_df %>% 
      select(-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and test dataset for product_category effect based on target encoding, include = FALSE}
enhance_datasets_using_product_category_effect <- function(product_category_effects,train_df,test_df,cleanup) {
  global_mean <- mean(train_df$number_of_hours)
  
  #we will use product category effects computed using training data in test data.
  train_df <- train_df %>% left_join(product_category_effects,by='product_category_name') %>%
    mutate(product_category_effect=if_else(is.na(product_category_effect),global_mean,product_category_effect))
        
  test_df <- test_df %>% left_join(product_category_effects,by='product_category_name')
  
  # cleanup
  if (cleanup) {
    train_df <- train_df %>% select(-product_category_name)
    test_df <- test_df %>% select(-product_category_name)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and test dataset for seller_id effect based on target encoding, include = FALSE}
enhance_datasets_using_seller_id_effect <- function(seller_id_effects,train_df,test_df,cleanup) {
  global_mean <- mean(train_df$number_of_hours)
  
  #we will use seller id effects computed using training data in test data.
  train_df <- train_df %>% left_join(seller_id_effects,by='seller_id') %>%
    mutate(seller_id_effect=if_else(is.na(seller_id_effect),global_mean,seller_id_effect))
        
  test_df <- test_df %>% left_join(seller_id_effects,by='seller_id')
  
  # cleanup
  if (cleanup) {
    train_df <- train_df %>% select(-seller_id)
    test_df <- test_df %>% select(-seller_id)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and test dataset for customer_state effect based on target encoding, include = FALSE}
enhance_datasets_using_customer_state_effect <- function(customer_state_effects,train_df,test_df,cleanup) {
  global_mean <- mean(train_df$number_of_hours)  
  
  #we will use customer state effects computed using training data in test data.
  train_df <- train_df %>% left_join(customer_state_effects,by='customer_state') %>%
    mutate(customer_state_effect=if_else(is.na(customer_state_effect),
                                         global_mean,
                                         customer_state_effect))
        
  test_df <- test_df %>% left_join(customer_state_effects,by='customer_state') 
  
  # cleanup
  if (cleanup) {
    train_df <- train_df %>% select(-customer_state)
    test_df <- test_df %>% select(-customer_state)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and test dataset for customer_loc effect based on target encoding, include = FALSE}
enhance_datasets_using_customer_loc_effect <- function(customer_loc_effects,train_df,test_df,cleanup) {
  global_mean <- mean(train_df$number_of_hours)
  
  #we will use customer loc effects computed using training data in test data.
  train_df <- train_df %>% 
    left_join(customer_loc_effects,by='customer_loc') %>%
    mutate(customer_loc_effect=if_else(is.na(customer_loc_effect),global_mean,customer_loc_effect))
        
  test_df <- test_df %>% left_join(customer_loc_effects,by='customer_loc')
  
  # cleanup
  if (cleanup) {
    train_df <- train_df %>% select(-customer_loc, -customer_zip_code_prefix)
    test_df <- test_df %>% select(-customer_loc, -customer_zip_code_prefix)
  }
  
  list(train_df,test_df)
}
```

```{r Enhance training and testing datasets with derived features, include =FALSE}
# uses training data to derive features and then enhances training and test set with those features
enhance_datasets_with_derived_features <- function(train_ds,test_ds,cleanup) {
  print('Adding column for delay in handover')

  delay_in_handover_to_carrier_data <- prepare_delay_in_handover_to_carrier(train_ds,0)
  
  dataset_list <- enhance_datasets_using_delay_in_handover_to_carrier(delay_in_handover_to_carrier_data,train_ds,test_ds,cleanup)
  train_ds <- dataset_list[[1]]
  test_ds <- dataset_list[[2]]
  
  print('Adding column for delay in payment approval')
  delay_in_payment_approval_data <- prepare_delay_in_payment_approval(train_ds,0)
  
  #we will use delay_in_payment_approval computed using training data in test data.
  dataset_list <- enhance_datasets_using_delay_in_payment_approval(delay_in_payment_approval_data,train_ds,test_ds,cleanup)

  dataset_list
}  
```

```{r Prepare data set for training, include = FALSE}
# prepares data for training and testing
# returns list of data frames. First list has training dataframe. Second list has test data frame
prepare_data_for_training_testing <- function(train_ds, test_ds, cleanup) {
  test_ds <- test_ds %>%
    semi_join(train_ds,by='product_category_name') %>%
    semi_join(train_ds,by='seller_id') %>% 
    semi_join(train_ds,by='customer_zip_code_prefix') %>% 
    semi_join(train_ds,by='customer_state') %>% 
    semi_join(train_ds,by='customer_loc')
  
  #adding derived features and target encoded categorical features
  print('Adding derived features')
  dataset_list <- enhance_datasets_with_derived_features(train_ds,test_ds,cleanup)
  train_ds <- dataset_list[[1]]
  test_ds <- dataset_list[[2]]
  
  print('Enhancing data for product category effects')
  weight_to_use <- target_encoding_weights %>% 
    filter(effect=='product_category') %>% 
    pull(weight)
  product_category_effects <- prepare_product_category_effect(train_ds,weight_to_use)
  dataset_list <- enhance_datasets_using_product_category_effect(product_category_effects,train_ds,test_ds,cleanup)
  train_ds <- dataset_list[[1]]
  test_ds <- dataset_list[[2]]

  print('Enhancing data for seller id effects')
  weight_to_use <- target_encoding_weights %>% filter(effect=='seller_id') %>% pull(weight)
  seller_id_effects <- prepare_seller_id_effect(train_ds,weight_to_use)
  dataset_list <- enhance_datasets_using_seller_id_effect(seller_id_effects,train_ds,test_ds,cleanup)
  train_ds <- dataset_list[[1]]
  test_ds <- dataset_list[[2]]
  
  print('Enhancing data for customer state effects')
  weight_to_use <- target_encoding_weights %>% filter(effect=='customer_state') %>% pull(weight)
  customer_state_effects <- prepare_customer_state_effect(train_ds,weight_to_use)
  dataset_list <- enhance_datasets_using_customer_state_effect(customer_state_effects,train_ds,test_ds,cleanup)
  train_ds <- dataset_list[[1]]
  test_ds <- dataset_list[[2]]
  
  print('Enhancing data for customer loc effects')
  weight_to_use <- target_encoding_weights %>% filter(effect=='customer_loc') %>% pull(weight)
  customer_loc_effects <- prepare_customer_loc_effect(train_ds,weight_to_use)
  dataset_list <- enhance_datasets_using_customer_loc_effect(customer_loc_effects,train_ds,test_ds,cleanup)
  dataset_list
}
```


### Product category effects
As part of this section, we looked into our intution that different product categories may have different delivery timelines and explored its influence by incoporating it in our model for analysis.

Since product categories are categorical in nature, we applied target encoding on the product categories attribute. 

===TODO talk about weight
===TODO talk about need of regularization.

Below histogram depicts how mean rating of movie across movies is distributed.


```{r Apply Target encoding for product_category_name, include = FALSE, eval=FALSE}
#TODO marked eval=FALSE to help generate report quickly
  train_subset_for_encoding <- train_subset[1:40000,] %>% select(-customer_loc, -customer_state)

  global_mean <- mean(train_subset_for_encoding$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_subset_for_encoding$number_of_hours,p=0.2,times=3,list=FALSE)
  
  weights <- seq(0,10,5)
  
  weight_to_use_per_partition <- sapply(1:3, function(index) {
  #lambda_data_set <- prepare_lambda_data_set(index)
  #train_lambda_set <- lambda_data_set[[1]]
  #test_lambda_set <- lambda_data_set[[2]]  
  train_weight_set <- train_subset_for_encoding[-test_weight_indices[,index],]
  test_weight_set <- train_subset_for_encoding[test_weight_indices[,index],]
  
  test_weight_set <- test_weight_set %>%
    semi_join(train_weight_set,by='product_category_name') %>%
    semi_join(train_weight_set,by='seller_id') %>%
    semi_join(train_weight_set,by='customer_zip_code_prefix')
  
  dataset_list <- enhance_datasets_with_derived_features(train_weight_set,test_weight_set,TRUE)
  train_weight_set <- dataset_list[[1]] %>% select(-seller_id)#,-customer_zip_code_prefix)
  test_weight_set <- dataset_list[[2]] %>% select(-seller_id)#,-customer_zip_code_prefix)
  
  weight_rmses <- sapply(weights, function(weight) {
      product_category_effects <- train_weight_set %>% 
        group_by(product_category_name) %>% 
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight*global_mean)/(n+weight)) %>% 
        select(-n)
      
      train_weight_set <- train_weight_set %>% left_join(product_category_effects,by='product_category_name') %>% rename(product_category_effect=mean) %>% select(-product_category_name)
      
      test_weight_set <- test_weight_set %>% left_join(product_category_effects,by='product_category_name') %>% rename(product_category_effect=mean) %>% select(-product_category_name)
      
      set.seed(seed=1,sample.kind = 'Rounding')
      preProcessScalingValues <- preProcess(train_weight_set %>% select(-number_of_hours), method = c("center", "scale"))
      
      scaled_train_subset <- predict(preProcessScalingValues, train_weight_set)
      scaled_test_subset <- predict(preProcessScalingValues, test_weight_set)
      
      # TODO remove below scaling was erroneous. train scaling needs to be used for test data
      # below is just demo of how to use scale
      # scaled_train_subset <- train_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale)) 
      # scaled_test_subset <- test_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale))
      
      # TODO can we skip modelling while evaluating weight to use or for target encoding?
      
      tuningControl=trainControl(method = "cv", number = 3, p = .8)
      knn_fit_for_weight <- train(number_of_hours~., scaled_train_subset, method='knn',tuneGrid=data.frame(k=c(34,41,48)),trControl=tuningControl)
      
      knn_fit_for_weight
      print(knn_fit_for_weight)
      
      predictions <- predict(knn_fit_for_weight,scaled_test_subset %>% select(-number_of_hours))

      RMSE(scaled_test_subset$number_of_hours,predictions) 
  })
  
  # selecting weight leading to lowest RMSE
  weight_to_use <- weights[which.min(weight_rmses)]
  paste('Weight to use: ', weight_to_use, ', corresponding RMSE: ', weight_rmses[which.min(weight_rmses)])

  print(weight_rmses)
  weight_to_use
})

weight_to_use_per_partition

weight_to_use <- mean(weight_to_use_per_partition)  
# 20/3

target_encoding_weights <- target_encoding_weights %>% add_row(effect='product_category',weight=weight_to_use)
```

```{r Apply Target encoding for seller_id, include = FALSE, eval=FALSE}
#TODO marked eval=FALSE to help generate report quickly
  train_subset_for_encoding <- train_subset[1:40000,] %>% select(-customer_loc, -customer_state)

  global_mean <- mean(train_subset_for_encoding$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_subset_for_encoding$number_of_hours,p=0.2,times=3,list=FALSE)
  
  weights <- seq(0,6,3)
  
  weight_to_use_per_partition <- sapply(1:3, function(index) {
  #lambda_data_set <- prepare_lambda_data_set(index)
  #train_lambda_set <- lambda_data_set[[1]]
  #test_lambda_set <- lambda_data_set[[2]]  
  train_weight_set <- train_subset_for_encoding[-test_weight_indices[,index],]
  test_weight_set <- train_subset_for_encoding[test_weight_indices[,index],]
  
  test_weight_set <- test_weight_set %>%
    semi_join(train_weight_set,by='product_category_name') %>%
    semi_join(train_weight_set,by='seller_id') %>% 
    semi_join(train_weight_set,by='customer_zip_code_prefix')
  
  ## adding derived features and target encoded categorical features
  dataset_list <- enhance_datasets_with_derived_features(train_weight_set,test_weight_set,FALSE)
  train_weight_set <- dataset_list[[1]]
  test_weight_set <- dataset_list[[2]]
  
  weight_to_use <- target_encoding_weights %>% 
    filter(effect=='product_category') %>% pull(weight)

  product_category_effects <- prepare_product_category_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_product_category_effect(product_category_effects,train_weight_set,test_weight_set,FALSE)

  train_weight_set <- dataset_list[[1]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  test_weight_set <- dataset_list[[2]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  ##
  
  weight_rmses <- sapply(weights, function(weight) {
      seller_id_effects <- train_weight_set %>% 
        group_by(seller_id) %>% 
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight*global_mean)/(n+weight)) %>% 
        select(-n)
      
      train_weight_set <- train_weight_set %>% left_join(seller_id_effects,by='seller_id') %>% rename(seller_id_effect=mean) %>% select(-seller_id)
      
      test_weight_set <- test_weight_set %>% left_join(seller_id_effects,by='seller_id') %>% rename(seller_id_effect=mean) %>% select(-seller_id)
      
      set.seed(seed=1,sample.kind = 'Rounding')
      preProcessScalingValues <- preProcess(train_weight_set %>% select(-number_of_hours), method = c("center", "scale"))
      
      scaled_train_subset <- predict(preProcessScalingValues, train_weight_set)
      scaled_test_subset <- predict(preProcessScalingValues, test_weight_set)
      
      # TODO remove below scaling was erroneous. train scaling needs to be used for test data
      # below is just demo of how to use scale
      # scaled_train_subset <- train_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale)) 
      # scaled_test_subset <- test_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale))
      
      # TODO can we skip modelling while evaluating weight to use or for target encoding?
      
      tuningControl=trainControl(method = "cv", number = 3, p = .8)
      knn_fit_for_weight <- train(number_of_hours~., scaled_train_subset, method='knn',tuneGrid=data.frame(k=c(34,41,48)),trControl=tuningControl)
      
      knn_fit_for_weight
      
      print(knn_fit_for_weight)
      
      predictions <- predict(knn_fit_for_weight,scaled_test_subset %>% select(-number_of_hours))

      RMSE(scaled_test_subset$number_of_hours,predictions) 
  })
  
  # selecting weight leading to lowest RMSE
  weight_to_use <- weights[which.min(weight_rmses)]
  paste('Weight to use: ', weight_to_use, ', corresponding RMSE: ', weight_rmses[which.min(weight_rmses)])

  print(weight_rmses)
  weight_to_use
})

weight_to_use_per_partition

weight_to_use <- mean(weight_to_use_per_partition)  
# 5

target_encoding_weights <- target_encoding_weights %>% add_row(effect='seller_id',weight=weight_to_use)
```

```{r Apply Target encoding for customer_state, include = FALSE,eval=FALSE}
#TODO marked eval=FALSE to help generate report quickly
  train_subset_for_encoding <- train_subset[1:40000,] %>% select(-customer_loc)
  global_mean <- mean(train_subset_for_encoding$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_subset_for_encoding$number_of_hours,p=0.2,times=3,list=FALSE)
  
  weights <- seq(0,30,15)
  
  weight_to_use_per_partition <- sapply(1:3, function(index) {
  #lambda_data_set <- prepare_lambda_data_set(index)
  #train_lambda_set <- lambda_data_set[[1]]
  #test_lambda_set <- lambda_data_set[[2]]  
  train_weight_set <- train_subset_for_encoding[-test_weight_indices[,index],]
  test_weight_set <- train_subset_for_encoding[test_weight_indices[,index],]
  
  test_weight_set <- test_weight_set %>% semi_join(train_weight_set,by='customer_state') 
  
  test_weight_set <- test_weight_set %>%
    semi_join(train_weight_set,by='product_category_name') %>%
    semi_join(train_weight_set,by='seller_id') %>% 
    semi_join(train_weight_set,by='customer_zip_code_prefix') %>% 
    semi_join(train_weight_set,by='customer_state')
  
  ## adding derived features and target encoded categorical features
  dataset_list <- enhance_datasets_with_derived_features(train_weight_set,test_weight_set,FALSE)
  train_weight_set <- dataset_list[[1]]
  test_weight_set <- dataset_list[[2]]
  
  weight_to_use <- target_encoding_weights %>% 
    filter(effect=='product_category') %>% pull(weight)

  product_category_effects <- prepare_product_category_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_product_category_effect(product_category_effects,train_weight_set,test_weight_set,FALSE)

  train_weight_set <- dataset_list[[1]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  test_weight_set <- dataset_list[[2]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  
  weight_to_use <- target_encoding_weights %>% filter(effect=='seller_id') %>% pull(weight)
  
  seller_id_effects <- prepare_seller_id_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_seller_id_effect(seller_id_effects,train_weight_set,test_weight_set,FALSE)

  train_weight_set <- dataset_list[[1]] %>% select(-seller_id)
  test_weight_set <- dataset_list[[2]] %>% select(-seller_id)
  ##
  
  weight_rmses <- sapply(weights, function(weight) {
      customer_state_effects <- train_weight_set %>% 
        group_by(customer_state) %>% 
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight*global_mean)/(n+weight)) %>% 
        select(-n)
      
      train_weight_set <- train_weight_set %>% left_join(customer_state_effects,by='customer_state') %>% rename(customer_state_effect=mean) %>% select(-customer_state) #-product_category_name
      
      test_weight_set <- test_weight_set %>% left_join(customer_state_effects,by='customer_state') %>% rename(customer_state_effect=mean) %>% select(-customer_state) # -product_category_name,
      
      set.seed(seed=1,sample.kind = 'Rounding')
      preProcessScalingValues <- preProcess(train_weight_set %>% select(-number_of_hours), method = c("center", "scale"))
      
      scaled_train_subset <- predict(preProcessScalingValues, train_weight_set)
      scaled_test_subset <- predict(preProcessScalingValues, test_weight_set)
      
      # TODO remove below scaling was erroneous. train scaling needs to be used for test data
      # below is just demo of how to use scale
      # scaled_train_subset <- train_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale)) 
      # scaled_test_subset <- test_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale))
      
      # TODO can we skip modelling while evaluating weight to use or for target encoding?
      
      tuningControl=trainControl(method = "cv", number = 3, p = .8)
      knn_fit_for_weight <- train(number_of_hours~., scaled_train_subset, method='knn',tuneGrid=data.frame(k=c(34,41,48)),trControl=tuningControl)
      
      knn_fit_for_weight
      
      print(knn_fit_for_weight)
      
      predictions <- predict(knn_fit_for_weight,scaled_test_subset %>% select(-number_of_hours))

      RMSE(scaled_test_subset$number_of_hours,predictions) 
  })
  
  # selecting weight leading to lowest RMSE
  weight_to_use <- weights[which.min(weight_rmses)]
  paste('Weight to use: ', weight_to_use, ', corresponding RMSE: ', weight_rmses[which.min(weight_rmses)])

  print(weight_rmses)
  weight_to_use
})

weight_to_use_per_partition

weight_to_use <- mean(weight_to_use_per_partition) 
# 10

target_encoding_weights <- target_encoding_weights %>%
  add_row(effect='customer_state',weight=weight_to_use)
```

```{r Apply Target encoding for customer_loc, include = FALSE,eval=FALSE}
#TODO marked eval=FALSE to help generate report quickly
  train_subset_for_encoding <- train_subset[1:40000,]
  global_mean <- mean(train_subset_for_encoding$number_of_hours)

  set.seed(1,sample.kind='Rounding')
  test_weight_indices <- createDataPartition(train_subset_for_encoding$number_of_hours,p=0.2,times=3,list=FALSE)
  
  weights <- seq(0,10,5)
  
  weight_to_use_per_partition <- sapply(1:3, function(index) {
  #lambda_data_set <- prepare_lambda_data_set(index)
  #train_lambda_set <- lambda_data_set[[1]]
  #test_lambda_set <- lambda_data_set[[2]]  
  train_weight_set <- train_subset_for_encoding[-test_weight_indices[,index],]
  test_weight_set <- train_subset_for_encoding[test_weight_indices[,index],]
  
  test_weight_set <- test_weight_set %>%
    semi_join(train_weight_set,by='product_category_name') %>%
    semi_join(train_weight_set,by='seller_id') %>% 
    semi_join(train_weight_set,by='customer_zip_code_prefix') %>% 
    semi_join(train_weight_set,by='customer_state') %>% 
    semi_join(train_weight_set,by='customer_loc')
  
  ## adding derived features and target encoded categorical features
  dataset_list <- enhance_datasets_with_derived_features(train_weight_set,test_weight_set,FALSE)
  train_weight_set <- dataset_list[[1]]
  test_weight_set <- dataset_list[[2]]
  
  weight_to_use <- target_encoding_weights %>% 
    filter(effect=='product_category') %>% pull(weight)

  product_category_effects <- prepare_product_category_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_product_category_effect(product_category_effects,train_weight_set,test_weight_set,FALSE)

  train_weight_set <- dataset_list[[1]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  test_weight_set <- dataset_list[[2]] %>% select(-order_purchase_timestamp,-handed_over_to_carrier_date,-shipping_limit_date,-customer_zip_code_prefix,-payment_approved_at,-product_category_name)
  
  weight_to_use <- target_encoding_weights %>% filter(effect=='seller_id') %>% pull(weight)
  
  seller_id_effects <- prepare_seller_id_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_seller_id_effect(seller_id_effects,train_weight_set,test_weight_set,FALSE)

  train_weight_set <- dataset_list[[1]] %>% select(-seller_id)
  test_weight_set <- dataset_list[[2]] %>% select(-seller_id)
  
  weight_to_use <- target_encoding_weights %>% filter(effect=='customer_state') %>% pull(weight)

  customer_state_effects <- prepare_customer_state_effect(train_weight_set,weight_to_use)
  dataset_list <- enhance_datasets_using_customer_state_effect(customer_state_effects,train_weight_set,test_weight_set,TRUE)

  train_weight_set <- dataset_list[[1]]
  test_weight_set <- dataset_list[[2]]
  ##
  
  weight_rmses <- sapply(weights, function(weight) {
      customer_loc_effects <- train_weight_set %>% 
        group_by(customer_loc) %>% 
        summarise(mean=mean(number_of_hours),n=n()) %>%
        mutate(mean=(n*mean+weight*global_mean)/(n+weight)) %>% 
        select(-n) %>% rename()
      
      train_weight_set <- train_weight_set %>% left_join(customer_loc_effects,by='customer_loc') %>% rename(customer_loc_effect=mean) %>% select(-customer_loc) #-product_category_name
      
      test_weight_set <- test_weight_set %>% left_join(customer_loc_effects,by='customer_loc') %>% rename(customer_loc_effect=mean) %>% select(-customer_loc) # -product_category_name,
      
      set.seed(seed=1,sample.kind = 'Rounding')
      preProcessScalingValues <- preProcess(train_weight_set %>% select(-number_of_hours), method = c("center", "scale"))
      
      scaled_train_subset <- predict(preProcessScalingValues, train_weight_set)
      scaled_test_subset <- predict(preProcessScalingValues, test_weight_set)
      
      # TODO remove below scaling was erroneous. train scaling needs to be used for test data
      # below is just demo of how to use scale
      # scaled_train_subset <- train_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale)) 
      # scaled_test_subset <- test_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale))
      
      # TODO can we skip modelling while evaluating weight to use or for target encoding?
      
      tuningControl=trainControl(method = "cv", number = 3, p = .8)
      knn_fit_for_weight <- train(number_of_hours~., scaled_train_subset, method='knn',tuneGrid=data.frame(k=c(34,41,48)),trControl=tuningControl)
      
      knn_fit_for_weight
      
      print(knn_fit_for_weight)
      
      predictions <- predict(knn_fit_for_weight,scaled_test_subset %>% select(-number_of_hours))

      RMSE(scaled_test_subset$number_of_hours,predictions) 
  })
  
  # selecting weight leading to lowest RMSE
  weight_to_use <- weights[which.min(weight_rmses)]
  paste('Weight to use: ', weight_to_use, ', corresponding RMSE: ', weight_rmses[which.min(weight_rmses)])

  print(weight_rmses)
  weight_to_use
})

weight_to_use_per_partition

weight_to_use <- mean(weight_to_use_per_partition) 
# 5

target_encoding_weights <- target_encoding_weights %>% add_row(effect='customer_loc',weight=weight_to_use)
```

```{r Save target encoding weights, include=FALSE, eval=FALSE}
save(target_encoding_weights,file='rda/target_encoding_weights.rda')
```

```{r Load target encoding weights, include=FALSE}
# required only to generate report or resume modeling quickly
load('rda/target_encoding_weights.rda')
```

penalty_data is computed on train_subset and is used with test_subset as historical learning of efficiency of each seller in delivering to carrier
Similarly delay in payment approval is used to incorporate role of customer zip code in delaying this processing, which maybe due to fraud analysis etc.
```{r Prepare training and test data for model tuning and development,include=FALSE}
dataset_list <- prepare_data_for_training_testing(train_subset,test_subset,FALSE)
train_subset <- dataset_list[[1]]
test_subset <- dataset_list[[2]]

# cleanup
train_subset <- train_subset %>%
  select(-handed_over_to_carrier_date,-shipping_limit_date,-product_category_name,-seller_id,-customer_state,-customer_loc,-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
test_subset <- test_subset %>%
  select(-handed_over_to_carrier_date,-shipping_limit_date,-product_category_name,-seller_id,-customer_state,-customer_loc,-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
```


5 fold cross validation
80/20 split
TODO remove p=0.8 from knn trainControl as it is not used.

```{r knn model data scaled under test, include=FALSE, eval=FALSE}
## TODO make echo=FALSE 
set.seed(seed=1,sample.kind = 'Rounding')
preProcessScalingValues <- preProcess(train_subset %>% select(-number_of_hours), method = c("center", "scale"))

scaled_train_subset <- predict(preProcessScalingValues, train_subset) 
scaled_test_subset <- predict(preProcessScalingValues, test_subset) 

# TODO remove below scaling was erroneous. train scaling needs to be used for test data
# below is just demo of how to use scale
# scaled_train_subset <- train_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale)) 
# scaled_test_subset <- test_subset %>% mutate(across(c(mean_delay_in_handover,distance_between_two_points,volume,product_weight_g,freight_value,price),scale))


tuningControl=trainControl(method = "cv", number = 5)
knn_fit <- train(number_of_hours~., scaled_train_subset, method='knn',tuneGrid=data.frame(k=c(56,63,70,77)),trControl=tuningControl)

knn_fit

predictions <- predict(knn_fit,scaled_test_subset %>% select(-number_of_hours))

performance_metric <- performance_metric %>% 
  add_row(type='Knn model(partial dataset)',
          value=RMSE((scaled_test_subset %>% pull(number_of_hours)),predictions))

performance_metric
#183.7767 for k=63

save(knn_fit,file='rda/knn_model.rda')
```


Regression problem.
Algorithms considered
- Random Forest
- knn - k nearest neighbors 
- gam


Random forest
However, it is important to know your data and keep in mind that a Random Forest can’t extrapolate. It can only make a prediction that is an average of previously observed labels. In this sense it is very similar to KNN.
In other words, in a regression problem, the range of predictions a Random Forest can make is bound by the highest and lowest labels in the training data. This behavior becomes problematic in situations where the training and prediction inputs differ in their range and/or distributions. This is called covariate shift and it is difficult for most models to handle but especially for Random Forest, because it can’t extrapolate.
From : https://towardsdatascience.com/a-limitation-of-random-forest-regression-db8ed7419e9f

```{r rf model, include= FALSE, eval = FALSE}
# TODO make it echo=FALSE
set.seed(seed=1,sample.kind = 'Rounding')
tuningControl=trainControl(method = "cv", number = 4)
rf_fit <- train(number_of_hours~., train_subset, method='rf',tuneGrid = data.frame(mtry = c(1,2,3,4,5)),trControl=tuningControl,ntree=200)
#rf_fit <- train(number_of_hours~., train_subset %>% select(-seller_state), method='rf',tuneGrid = data.frame(mtry = seq(5, 50, 10)),trControl=tuningControl,ntree=250) # nodesize = 50,maxnodes=2000,ntree=200

rf_fit

predictions <- predict(rf_fit,test_subset %>% select(-number_of_hours))

performance_metric <- performance_metric %>% 
  add_row(type='Random forest model(partial dataset)',
          value=RMSE((test_subset %>% pull(number_of_hours)),predictions))

performance_metric
# 174.2496 for mtry 2. Technically there are total of 11 predictors. The seller_state was not of much help. it was actually increasing RMSE. So have ignored it.

save(rf_fit,file='rda/rf_model.rda')
```

```{r Save performance metric, include=FALSE, eval=FALSE}
save(performance_metric,file='rda/performance_metric.rda')
```

```{r Load performance metric, include=FALSE}
# required only to generate report
load('rda/performance_metric.rda')
```


```{r ensemble, include=FALSE, eval= FALSE}
load('rda/knn_model.rda')
load('rda/rf_model.rda')

predictions_knn <- predict(knn_fit,scaled_test_subset %>% select(-number_of_hours))
predictions_rf <- predict(rf_fit,test_subset %>% select(-number_of_hours))

predictions_df <- data.frame(predictions_knn,predictions_rf)

RMSE(rowMeans(predictions_df),(test_subset %>% pull(number_of_hours) ))
176.5041
```



```{r Prepare dataset for final model training, include = FALSE}
set.seed(seed=1,sample.kind = 'Rounding')

validation_dataset <- validation_dataset %>% 
  compute_volume_using_product_info() %>% 
  extract_distance_between_seller_customer() %>% 
  compute_rough_customer_location()

dataset_list <- prepare_data_for_training_testing(training_dataset,validation_dataset,FALSE)
training_dataset <- dataset_list[[1]]
validation_dataset <- dataset_list[[2]]

# cleanup
training_dataset <- training_dataset %>%
  select(-handed_over_to_carrier_date,-shipping_limit_date,-product_category_name,-seller_id,-customer_state,-customer_loc,-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
validation_dataset <- validation_dataset %>%
  select(-handed_over_to_carrier_date,-shipping_limit_date,-product_category_name,-seller_id,-customer_state,-customer_loc,-customer_zip_code_prefix,-order_purchase_timestamp,-payment_approved_at)
```


```{r Final Model Training, include=FALSE,eval = FALSE}
# TODO marked eval=FALSE to prevent it from running during report generation
set.seed(seed=1,sample.kind = 'Rounding')

mtry_to_use <- rf_fit$finalModel$mtry
ntree_to_use <- 500 #rf_fit$finalModel$ntree

final_model <- randomForest(number_of_hours~., training_dataset,mtry= mtry_to_use, ntree=ntree_to_use)

final_model

save(final_model,file='rda/final_model.rda')
```


```{r Final model validation, include = FALSE, eval=FALSE}
# TODO marked eval=FALSE to prevent it from running during report generation
predictions <- predict(final_model,validation_dataset %>% select(-number_of_hours))

performance_metric <- performance_metric %>% 
  add_row(type='Final model',
          value=RMSE((validation_dataset %>% pull(number_of_hours) ),predictions))
# 189.2705 for mtry=2, ntree=500

performance_metric
```



five sets each having a training set and testing set. This ensured that we used only edx dataset while we developed our model. In addition, the multiple partitions helped to remove any randomness from our tuning parameters and to get an appopriate estimate of performance for our incremental model. This helped reduced the probability of overfitting.





we should consider if we need time stamp or we can take purchase time as 0 and calculated approved at from it. though we may lose granularity in terms of time as truck may come everyday at 4. so after 4 you can ship , before 4 you cant
We can be agnostic to purchase time and just predict number of hours for delivery for given purchase.
 
TODO -> if there is delayed to carrier precendence, we could use that probability and average delay to carrier to fine tune our results. Similarly we could use other metrics like payment approval time etc.